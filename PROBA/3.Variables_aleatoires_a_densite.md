<h5 style="text-align: center"> PROBABILITES </h5>

------

## **Variables aléatoires à densité**

---

### Densité de probabilité


| Définition                                                   |
| :----------------------------------------------------------- |
| **<u>Densité de probabilité</u>** : $p:I \rightarrow \Bbb R^+$ telle que $\int_I p_X(x)dx=1$ |

| Exemples                             |                                  |                                                              |
| :----------------------------------- | :------------------------------: | :----------------------------------------------------------: |
| Densité **uniforme**                 |      $X\sim\mathcal U(a,b)$      |         $p(x)={1\over |b-a|} \mathbf{1}_{[a,b]}(x)$          |
| Densité **exponentielle**            |    $X\sim\mathcal E(\lambda)$    |    $p(x)=\lambda e^{-\lambda x} \mathbf 1_{\Bbb R^+}(x)$     |
| Densité **normale** / **gaussienne** | $X\sim \mathcal N(\mu,\sigma^2)$ | $p(x)={1 \over \sqrt{2\pi \sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$ |

| Propriétés                        |
| :-------------------------------- |
| $P(X\in [a,b]) = \int_a^b p(x)dx$ |
| $P(X=x)=0$                        |

---

### Fonction de répartition


| Définition                                                   |
| :----------------------------------------------------------- |
| **<u>Fonction de distribution / répartition</u>** : $F(x)=P(X\leq x)=\int_{-\infty}^x p(x)dx$ |

On a alors : $F'(x)=p(x)$ et $P(X\in [a,b])=F(b)-F(a)$

| <u>**Changement de variable**</u>                            |
| :----------------------------------------------------------- |
| $Y=\varphi(X)$ où $\varphi$ est une fonction strictement croissante. Alors : |
| $F_Y(y)=F_X(\varphi^{-1}(y))$                                |
| $p_Y(y)={1 \over \varphi'(\varphi^{-1}(y))}\cdot p_X(\varphi^{-1}(y))$ |

---

### Espérance, moment, fonction génératrice


| <u>**Espérance**</u>                         |
| :------------------------------------------- |
| $E(f(X))=\int_{-\infty}^{+\infty}f(x)p(x)dx$ |

| <u>**Moment**</u>                                            |
| :----------------------------------------------------------- |
| Moment d’ordre $n$ : $m_n=E(X^n)=\int x^np(x)dx$             |
| Moment centré d’ordre $n$ : $\mu_n=E((X-E(X))^n)=\int (x-E(X))^np(x)dx$ |

| <u>**Fonction génératrice des moments**</u>                  |
| :----------------------------------------------------------- |
| $\mathcal M_X(u)=E(e^{ux})=\int_{-\infty}^{+\infty}e^{ux}p(x)dx$ |

Si $m_n$ existe, $m_n=\mathcal M_X^{(n)}(0)$

---

### Couple de variables aléatoires

| <u>**Couples et vecteurs aléatoires**</u>                    |
| :----------------------------------------------------------- |
| Le couple $(X,Y)$ est de densité $p_{X,Y}$ si pour tous intervalles $[a_1,b_1],[a_2,b_2]$, $P(X\in[a_1,b_1] \cap Y\in [a_2,b_2])=\int_{a_1}^{b_1} \int_{a_2}^{b_2} p_{X,Y}(x,y)dxdy$ |

| <u>**Marginalisation**</u>                       |
| :----------------------------------------------- |
| $p_X(x)=\int_{-\infty}^{+\infty} p_{X,Y}(x,y)dy$ |
| $p_Y(y)=\int_{-\infty}^{+\infty} p_{X,Y}(x,y)dx$ |

| <u>**Indépendance**</u>                                      |
| :----------------------------------------------------------- |
| $X$ et $Y$ indépendantes $\iff p_{X,Y}(x,y)=p_X(x)\cdot p_Y(y)$ |

| **<u>Changement de variable</u>**                            |
| :----------------------------------------------------------- |
| $(X,Y) \sim p_{X,Y}, (W,Z)=\varphi (X,Y)$ où $\varphi:\Bbb R^2 \rightarrow \Bbb R^2$ |
| $p_{W,Z}=p_{X,Y}(\varphi^{-1}(w,z)) \cdot |\det(D\varphi^{-1}(w,z))|$ |

​	Où $D\varphi^{-1}$ est la matrice $D\varphi^{-1}= \begin{bmatrix} {\partial x \over \partial w} & {\partial x \over \partial z} \\ {\partial y \over \partial w} & {\partial y \over \partial z} \end{bmatrix}$

| <u>**Loi et espérance conditionnelle**</u>                   |
| :----------------------------------------------------------- |
| Densité de $X$ conditionnée à $Y=y$ :  $p_{X|Y=y}(x)={p_{X,Y}(x,y) \over p_Y(y)}$ |
| Espérance de $X$ conditionnée à $Y=y$ :  $E(X|Y=y)=\int_{-\infty}^{+\infty}x \cdot p_{X|Y=y}(x)dx$ |

- L’espérance conditionnelle est aléatoire car elle dépend de la valeur de $Y$

- On appelle **fonction de régression** $g(y)=E(X|Y=y)$

  $g$ minimise l’erreur quadratique moyenne $\varepsilon_f=E(|X-f(y)|^2)$ 

---

### Vecteurs gaussiens

| <u>**Fonction génératrice des moments**</u>                  |
| :----------------------------------------------------------- |
| Pour un vecteur aléatoire $Z : \Omega \rightarrow \R^n$ et un vecteur $u \in \R^n$,<br />$\mathcal M_Z(u)=E(e^{^tuz})=E\left( \exp{\left( \sum\limits_{i=1}^{n} u_iz_i \right)} \right)$ |

- Si $X,Y : \Omega \rightarrow \R^n$ indépendantes et $S=X+Y$, alors $\mathcal M_S(u) = \mathcal M_X(u) \cdot \mathcal M_Y(u)$

| <u>Théorème</u>                                              |
| :----------------------------------------------------------- |
| Soit $Z=(X,Y)$ avec $X\in\R^p, Y\in\R^q$ tels que $p+q=n$<br />$X$ et $Y$ indépendants $\iff \mathcal M_Z(u)=\mathcal M_X(v)+\mathcal M_Y(w)$   où $\left\{ \begin{array}{} v&=(u_1,\cdots,u_p) \\ w&= (u_{p+1},\cdots,u_n) \end{array} \right.$ |



---

<table width="90%">
<tr>
<td style="width: 30%; text-align: left; background:transparent; border:0;">Mathématiques</td>
<td style="width: 30%; text-align: center; background:transparent; border:0;">Alexis Bagarre</td>
<td style="width: 30%; text-align: right; background:transparent; border:0;">T1 - 2018 / 2019</td>
</tr>
</table>