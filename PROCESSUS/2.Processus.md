<h5 style="text-align: center"> PROCESSUS ALEATOIRES </h5>

------

## **Processus aléatoire**

---

### Définition

| Définition                                                   |
| :----------------------------------------------------------- |
| Un <u>**processus aléatoire**</u> est une famille de variables aléatoires $X(\omega, t)$ dépendant de la réalisation de $\omega$ et de $t$ |

- Pour $t$ fixé, $X(\omega)$ est une variable aléatoire

- Pour $\omega$ fixé, $X(t)$ est une fonction dépendant uniquement de $t$ (appelée “trajectoire du processus”). On dit que c’est la réalisation d’un processus aléatoire, un échantillon du processus aléatoire ou une observation du processus aléatoire


  Types : 

  - Continu : mesurable à chaque instant ; notation $X(t)$

  - Discret : échantillonnage d’un signal continu par exemple ; notation $X(n)$


  Adaptation des notions de probabilité :

  - Espérance : $m_X(t) = E(X(t))=\int x \cdot p_X(x,t) dx$
  - Fonction de répartition : $F(x,t)=P\left(X(t)\leq x\right)$
  - Densité de probabilité : $p(x,t)=\frac{\partial F(x,t)}{\partial x}$
  - Variance : $Var(X(t))=\int \bigl( x-E(X(t)) \bigr)^2 \cdot p(x,t)dx$
  - Écart type : $\sigma(t)=\left( Var(x) \right)^{1/2}$

---

### Étude de la corrélation entre 2 instants

- #### Pour 1 processus

  | <u>**Fonction d’*auto*corrélation**</u> |
  | :-------------------------------------- |
  | $R_{XX}(t_1,t_2)=E[X(t_1)X^*(t_2)]$     |

  | <u>**Fonction d’*auto*covariance**</u>                       |
  | :----------------------------------------------------------- |
  | $C_{XX}(t_1,t_2)=E\Bigl[ \bigl( X(t_1)-E[X(t_1)] \bigr) \cdot \bigl(X(t_2)-E[X(t_2)] \bigr)^*\Bigr] = R_{XX}(t_1,t_2)-\mu(t_1)\mu^*(t_2)$ |

- #### Pour 2 processus

  | <u>**Fonction d’*inter*corrélation**</u> |
  | :--------------------------------------- |
  | $R_{XY}(t_1,t_2)=E[X(t_1)Y^*(t_2)]$      |

  | <u>**Fonction d’*inter*covariance**</u>                      |
  | :----------------------------------------------------------- |
  | $C_{XY}(t_1,t_2)=E\Bigl[\bigl( X(t_1)-E[X(t_1)] \bigr) \cdot \bigl(Y(t_2)-E[Y(t_2)] \bigr)^*\Bigr]$ |

---

### Processus stationnaire

| Définition                                                   |
| :----------------------------------------------------------- |
| Un processus stationnaire au sens large est un processus tel que : |
| &bull; Son espérance est constante                           |
| &bull; $R_{XX}$ est fonction d’une seule variable (l’écart)  |
| &bull; $R_{XX}(0)<+\infty$                                   |

  - $R_{XX}(-\tau)={R_{XX}}^*(\tau)$
  - $R_{XX}(0)=E(|X(t)|^2)\geq 0$
  - $\forall \tau, |R_{XX}(\tau)|\leq R_{XX}(0)$

---

### Bruit Blanc Gaussien Centré (BBGC)

- Blanc : $r_{bb}(\tau)=\sigma_b^2\cdot\delta(\tau)$
- Gaussien : $b=(b_1,\cdots,b_n)$ de densité conjointe gaussienne
- Centré : $E(b(k))=0$

Exemple : agitation des électrons à une certaines température (bruit thermique)

---

### Autres processus

- Processus à **moyenne ajustée (MA)** (Moving Average)
  - $\pmb{x(k)=\sum\limits_{i=0}^q b_j} \cdot \underbrace{\pmb{u(k-j)}}_{\text{BBGC}}$
  - $q$ est l’ordre
- Processus **auto-régressif (AR)**
  - $\pmb{x(k)=-}\underbrace{\pmb{\sum\limits_{i=1}^n a_i \cdot x(k-i)}}_{\begin{array}{center} \text{prédiction de }x(k) \text{ fondée} \\ \text{sur les } p \text{ dernières valeurs}\end{array}} + \underbrace{\pmb{u(k)}}_{\begin{array}{ceter}\text{BBGC} \\ \text{erreur de} \\ \text{prédiction}\end{array}}$
- Processus **ARMA**
  - $\pmb{x(k)=-\sum\limits_{i=1}^p a_i \cdot x(k-i) + \sum\limits_{j=0}^q b_j \cdot u(k-j)}$
  - $a_i$ : paramètre AR
  - $b_j$ : paramètre MA
- Processus **TVAR** (Time Varying AR)
  - $\pmb{x(k)=-\sum\limits_{i=1}^p a_i(k) \cdot x(k-i) + u(k)}$

---

### Vecteurs aléatoires

- $\underline X = \begin{bmatrix} x_1(k) \\ x_2(k) \\ \vdots \\ x_N(k) \end{bmatrix} \text{ et } E[\underline X] = \begin{bmatrix} E[x_1(k)] \\ E[x_2(k)] \\ \vdots \\ E[x_N(k)] \end{bmatrix}$

- Matrice de corrélation : $R_X=E[\underline X \underline X^H]=\begin{bmatrix}
  E[x_1(k)^2] & E[x_1(k)x_2(k)] & \cdots & \cdots \\
  E[x_2(k)x_1(k)] & E[x_2(k)^2] & \cdots & \cdots \\
  \vdots & \vdots & \ddots & \vdots \\
  E[x_N(k)x_1(k)] & \cdots & \cdots & E[x_N(k)^2]
  \end{bmatrix}$
- Pour un BBGC : $E[\underline X \underline X^T]=\sigma_b^2 I_N$
  - Structure de **Toeplitz** : valeurs identiques sur les diagonlales
  - Symétrique dans le cas réel, symétrique hermitienne dans le cas complexe
  - Semi définie positive

---

### Ergodicité

- Substitution de la moyenne mathématiques (sur les échantillons) à la moyenne temporelle et estimation de la fonction d’autocorrélation
  - $\mu=E[X(t)]=\lim\limits_{T\rightarrow +\infty}{1 \over T} \int_T x(t)dt$
  - $R_{XX}(\tau)=E[X(k)X(k-\tau)^*]=\lim\limits_{T\rightarrow +\infty} {1 \over T} \int_T x(t)\cdot x^*(t-\tau)dt$
- **Estimateurs** de la fonction d’autocorrélation
  - Estimateur **non biaisé** : $\widehat{R}_{XX}(\tau)=\cfrac{1}{N-\tau} \sum\limits_{k=\tau}^{N-1}x(k)\cdot x^*(k-\tau)$
  - Estimateur **biaisé** : $\widetilde{R}_{XX}(\tau)=\cfrac{1}{N} \sum\limits_{k=\tau}^{N-1}x(k)\cdot x^*(k-\tau)$  (asymptotiquement non biaisé)

---

<table width="90%">
<tr>
<td style="width: 30%; text-align: left; background:transparent; border:0;">Processus Aléatoires</td>
<td style="width: 30%; text-align: center; background:transparent; border:0;">Alexis Bagarre</td>
<td style="width: 30%; text-align: right; background:transparent; border:0;">T1 - 2018 / 2019</td>
</tr>
</table>